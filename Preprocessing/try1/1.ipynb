{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:15:45.651638Z",
     "start_time": "2024-11-12T22:15:44.115809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Dataset (2).xlsx')"
   ],
   "id": "d054762b03330f31",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:15:45.677853Z",
     "start_time": "2024-11-12T22:15:45.661646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter out 'unknown' race instances\n",
    "df = df[~df['Race'].isin(['Unknown'])]\n",
    "del df['Gender']\n",
    "print(df)"
   ],
   "id": "fd4d835c84b2b4f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Age       Race  CatsInHouse  \\\n",
      "0       Less than 1 year     Birman            3   \n",
      "1       Less than 1 year     Birman            1   \n",
      "2             2-10 years   European            4   \n",
      "3       Less than 1 year   European            1   \n",
      "4              1-2 years     Birman            2   \n",
      "...                  ...        ...          ...   \n",
      "3138          2-10 years    Persian            1   \n",
      "3139    Less than 1 year  MaineCoon            3   \n",
      "3140  More than 10 years      Other            1   \n",
      "3141    Less than 1 year     Bengal            1   \n",
      "3142    Less than 1 year     Bengal            5   \n",
      "\n",
      "                            HousingType       Zone  TimeOutside  \\\n",
      "0             Apartment without balcony      Urban            0   \n",
      "1     Apartment with balcony or terrace      Urban            0   \n",
      "2                House in a subdivision      Urban            0   \n",
      "3                House in a subdivision      Rural            2   \n",
      "4                 Individual house zone      Rural            1   \n",
      "...                                 ...        ...          ...   \n",
      "3138              Individual house zone      Rural            0   \n",
      "3139              Individual house zone      Rural            0   \n",
      "3140              Individual house zone  Periurban            2   \n",
      "3141             House in a subdivision      Rural            0   \n",
      "3142             House in a subdivision  Periurban            0   \n",
      "\n",
      "      TimeWithOwner  Shy  Calm  Skittish  ...  Loner  Ferocious  Territorial  \\\n",
      "0                 0    1     1         1  ...      1          1            1   \n",
      "1                 2    1     1         3  ...      1          2            2   \n",
      "2                 2    4     4         3  ...      2          1            1   \n",
      "3                 2    3     2         2  ...      3          4            3   \n",
      "4                 2    1     4         1  ...      1          2            4   \n",
      "...             ...  ...   ...       ...  ...    ...        ...          ...   \n",
      "3138              3    4     2         5  ...      4          1            1   \n",
      "3139              3    2     2         1  ...      2          1            2   \n",
      "3140              3    1     4         2  ...      3          1            4   \n",
      "3141              2    2     4         3  ...      3          1            2   \n",
      "3142              2    2     2         1  ...      2          3            5   \n",
      "\n",
      "      Aggressive  Impulsive  Predictable  Inattentive  NaturalAreasAbundance  \\\n",
      "0              1          1            1            1                Unknown   \n",
      "1              3          4            4            3                Unknown   \n",
      "2              1          2            4            2                Unknown   \n",
      "3              3          3            4            4                      3   \n",
      "4              1          4            3            3                      3   \n",
      "...          ...        ...          ...          ...                    ...   \n",
      "3138           1          1            3            4                      3   \n",
      "3139           1          2            2            2                      3   \n",
      "3140           4          3            4            2                      3   \n",
      "3141           3          1            3            5                      3   \n",
      "3142           4          5            2            3                      3   \n",
      "\n",
      "      BirdsEater  MiceEater  \n",
      "0              4          4  \n",
      "1              0          0  \n",
      "2              0          0  \n",
      "3              0          0  \n",
      "4              0          0  \n",
      "...          ...        ...  \n",
      "3138           0          0  \n",
      "3139           0          0  \n",
      "3140           0          1  \n",
      "3141           0          0  \n",
      "3142           0          0  \n",
      "\n",
      "[3063 rows x 25 columns]\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:15:45.788316Z",
     "start_time": "2024-11-12T22:15:45.765712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the mean of numeric values\n",
    "numeric_mask = df['NaturalAreasAbundance'] != 'Unknown'\n",
    "mean_value = pd.to_numeric(df[numeric_mask]['NaturalAreasAbundance']).mean()\n",
    "\n",
    "# Replace 'Unknown' with the mean value and round to nearest integer\n",
    "df['NaturalAreasAbundance'] = df['NaturalAreasAbundance'].replace('Unknown', mean_value)\n",
    "df['NaturalAreasAbundance'] = df['NaturalAreasAbundance'].astype(float).round().astype(int)\n",
    "print(df.info())"
   ],
   "id": "7f1a9eb087c13737",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3063 entries, 0 to 3142\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Age                    3063 non-null   object\n",
      " 1   Race                   3063 non-null   object\n",
      " 2   CatsInHouse            3063 non-null   int64 \n",
      " 3   HousingType            3063 non-null   object\n",
      " 4   Zone                   3063 non-null   object\n",
      " 5   TimeOutside            3063 non-null   int64 \n",
      " 6   TimeWithOwner          3063 non-null   int64 \n",
      " 7   Shy                    3063 non-null   int64 \n",
      " 8   Calm                   3063 non-null   int64 \n",
      " 9   Skittish               3063 non-null   int64 \n",
      " 10  Intelligent            3063 non-null   int64 \n",
      " 11  Vigilant               3063 non-null   int64 \n",
      " 12  Tenacious              3063 non-null   int64 \n",
      " 13  Affectionate           3063 non-null   int64 \n",
      " 14  Friendly               3063 non-null   int64 \n",
      " 15  Loner                  3063 non-null   int64 \n",
      " 16  Ferocious              3063 non-null   int64 \n",
      " 17  Territorial            3063 non-null   int64 \n",
      " 18  Aggressive             3063 non-null   int64 \n",
      " 19  Impulsive              3063 non-null   int64 \n",
      " 20  Predictable            3063 non-null   int64 \n",
      " 21  Inattentive            3063 non-null   int64 \n",
      " 22  NaturalAreasAbundance  3063 non-null   int32 \n",
      " 23  BirdsEater             3063 non-null   int64 \n",
      " 24  MiceEater              3063 non-null   int64 \n",
      "dtypes: int32(1), int64(20), object(4)\n",
      "memory usage: 610.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:15:45.897354Z",
     "start_time": "2024-11-12T22:15:45.878621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def create_stratified_split(df, stratify_col='Race', test_size=0.1, random_state=42):\n",
    "    # Create the train/test split while maintaining the same proportions of Race\n",
    "    train_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=df[stratify_col]\n",
    "    )\n",
    "    \n",
    "    # Verify the proportions\n",
    "    print(\"\\nRace proportions in original dataset:\")\n",
    "    print(df[stratify_col].value_counts(normalize=True))\n",
    "    \n",
    "    print(\"\\nRace proportions in larger split (90%):\")\n",
    "    print(train_df[stratify_col].value_counts(normalize=True))\n",
    "    \n",
    "    print(\"\\nRace proportions in smaller split (10%):\")\n",
    "    print(test_df[stratify_col].value_counts(normalize=True))\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "df, test_df = create_stratified_split(df)\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"Larger split (90%): {len(df)} rows\")\n",
    "print(f\"Smaller split (10%): {len(test_df)} rows\")"
   ],
   "id": "8e926cde6ef08388",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Race proportions in original dataset:\n",
      "Race\n",
      "European            0.333660\n",
      "NoBreed             0.157689\n",
      "Bengal              0.078028\n",
      "Ragdoll             0.070846\n",
      "MaineCoon           0.064643\n",
      "Birman              0.062684\n",
      "Persian             0.062684\n",
      "BritishShorthair    0.054195\n",
      "Other               0.044074\n",
      "Sphynx              0.024812\n",
      "Siamese             0.018936\n",
      "Chartreux           0.010121\n",
      "TurkishAngora       0.009141\n",
      "Savannah            0.008488\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race proportions in larger split (90%):\n",
      "Race\n",
      "European            0.333817\n",
      "NoBreed             0.157837\n",
      "Bengal              0.078012\n",
      "Ragdoll             0.070755\n",
      "MaineCoon           0.064586\n",
      "Persian             0.062772\n",
      "Birman              0.062772\n",
      "BritishShorthair    0.054064\n",
      "Other               0.044267\n",
      "Sphynx              0.024673\n",
      "Siamese             0.018868\n",
      "Chartreux           0.010160\n",
      "TurkishAngora       0.009071\n",
      "Savannah            0.008345\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race proportions in smaller split (10%):\n",
      "Race\n",
      "European            0.332248\n",
      "NoBreed             0.156352\n",
      "Bengal              0.078176\n",
      "Ragdoll             0.071661\n",
      "MaineCoon           0.065147\n",
      "Persian             0.061889\n",
      "Birman              0.061889\n",
      "BritishShorthair    0.055375\n",
      "Other               0.042345\n",
      "Sphynx              0.026059\n",
      "Siamese             0.019544\n",
      "Chartreux           0.009772\n",
      "Savannah            0.009772\n",
      "TurkishAngora       0.009772\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Split sizes:\n",
      "Larger split (90%): 2756 rows\n",
      "Smaller split (10%): 307 rows\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:15:46.022129Z",
     "start_time": "2024-11-12T22:15:45.987106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform_dataset(df):\n",
    "    \"\"\"\n",
    "    Transform the dataset by:\n",
    "    1. Mapping age values to numeric\n",
    "    2. One-hot encoding HousingType, Zone, and Race\n",
    "    \n",
    "    Args:\n",
    "    df (pandas.DataFrame): Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Transformed DataFrame\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame\n",
    "    df_transformed = df.copy()\n",
    "    \n",
    "    # Age mapping\n",
    "    age_mapping = {\n",
    "        'Less than 1 year': 0.5,\n",
    "        '1-2 years': 1.5,\n",
    "        '2-10 years': 6,\n",
    "        'More than 10 years': 12\n",
    "    }\n",
    "    \n",
    "    # Apply age mapping\n",
    "    df_transformed['Age'] = df_transformed['Age'].map(age_mapping)\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    categorical_columns = ['HousingType', 'Zone', 'Race']\n",
    "    \n",
    "    # Create one-hot encoded columns\n",
    "    for column in categorical_columns:\n",
    "        one_hot = pd.get_dummies(df_transformed[column], prefix=column)\n",
    "        \n",
    "        # Add one-hot encoded columns to the transformed DataFrame\n",
    "        df_transformed = pd.concat([df_transformed, one_hot], axis=1)\n",
    "        \n",
    "        # Drop the original categorical column\n",
    "        df_transformed = df_transformed.drop(column, axis=1)\n",
    "    \n",
    "    return df_transformed\n",
    "\n",
    "# Example usage:\n",
    "df = transform_dataset(df)\n",
    "test_df = transform_dataset(test_df)\n",
    "\n",
    "df.info()"
   ],
   "id": "f4759d797d422571",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2756 entries, 1053 to 1321\n",
      "Data columns (total 43 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Age                                            2756 non-null   float64\n",
      " 1   CatsInHouse                                    2756 non-null   int64  \n",
      " 2   TimeOutside                                    2756 non-null   int64  \n",
      " 3   TimeWithOwner                                  2756 non-null   int64  \n",
      " 4   Shy                                            2756 non-null   int64  \n",
      " 5   Calm                                           2756 non-null   int64  \n",
      " 6   Skittish                                       2756 non-null   int64  \n",
      " 7   Intelligent                                    2756 non-null   int64  \n",
      " 8   Vigilant                                       2756 non-null   int64  \n",
      " 9   Tenacious                                      2756 non-null   int64  \n",
      " 10  Affectionate                                   2756 non-null   int64  \n",
      " 11  Friendly                                       2756 non-null   int64  \n",
      " 12  Loner                                          2756 non-null   int64  \n",
      " 13  Ferocious                                      2756 non-null   int64  \n",
      " 14  Territorial                                    2756 non-null   int64  \n",
      " 15  Aggressive                                     2756 non-null   int64  \n",
      " 16  Impulsive                                      2756 non-null   int64  \n",
      " 17  Predictable                                    2756 non-null   int64  \n",
      " 18  Inattentive                                    2756 non-null   int64  \n",
      " 19  NaturalAreasAbundance                          2756 non-null   int32  \n",
      " 20  BirdsEater                                     2756 non-null   int64  \n",
      " 21  MiceEater                                      2756 non-null   int64  \n",
      " 22  HousingType_Apartment with balcony or terrace  2756 non-null   bool   \n",
      " 23  HousingType_Apartment without balcony          2756 non-null   bool   \n",
      " 24  HousingType_House in a subdivision             2756 non-null   bool   \n",
      " 25  HousingType_Individual house zone              2756 non-null   bool   \n",
      " 26  Zone_Periurban                                 2756 non-null   bool   \n",
      " 27  Zone_Rural                                     2756 non-null   bool   \n",
      " 28  Zone_Urban                                     2756 non-null   bool   \n",
      " 29  Race_Bengal                                    2756 non-null   bool   \n",
      " 30  Race_Birman                                    2756 non-null   bool   \n",
      " 31  Race_BritishShorthair                          2756 non-null   bool   \n",
      " 32  Race_Chartreux                                 2756 non-null   bool   \n",
      " 33  Race_European                                  2756 non-null   bool   \n",
      " 34  Race_MaineCoon                                 2756 non-null   bool   \n",
      " 35  Race_NoBreed                                   2756 non-null   bool   \n",
      " 36  Race_Other                                     2756 non-null   bool   \n",
      " 37  Race_Persian                                   2756 non-null   bool   \n",
      " 38  Race_Ragdoll                                   2756 non-null   bool   \n",
      " 39  Race_Savannah                                  2756 non-null   bool   \n",
      " 40  Race_Siamese                                   2756 non-null   bool   \n",
      " 41  Race_Sphynx                                    2756 non-null   bool   \n",
      " 42  Race_TurkishAngora                             2756 non-null   bool   \n",
      "dtypes: bool(21), float64(1), int32(1), int64(20)\n",
      "memory usage: 541.0 KB\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:15:46.299105Z",
     "start_time": "2024-11-12T22:15:46.107083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def balance_cat_races(df, min_class_size=None, max_class_size=None):\n",
    "    \"\"\"\n",
    "    Balance cat race classes using SMOTE for underrepresented classes and random undersampling\n",
    "    for overrepresented classes.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe with cat features and race columns\n",
    "    min_class_size (int): Minimum size for each race class (default: None)\n",
    "    max_class_size (int): Maximum size for each race class (default: None)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Balanced dataframe\n",
    "    dict: Class distribution before and after balancing\n",
    "    \"\"\"\n",
    "    # Get race columns\n",
    "    race_cols = [col for col in df.columns if col.startswith('Race_')]\n",
    "    \n",
    "    # Get features (all columns except race columns)\n",
    "    feature_cols = [col for col in df.columns if col not in race_cols]\n",
    "    \n",
    "    # Create y label (convert one-hot encoded races to single column)\n",
    "    y = np.argmax([df[col].values for col in race_cols], axis=0)\n",
    "    X = df[feature_cols].copy()\n",
    "    \n",
    "    # Get initial class distribution\n",
    "    initial_distribution = dict(Counter(y))\n",
    "    \n",
    "    # If min_class_size is not specified, use the median class size\n",
    "    if min_class_size is None:\n",
    "        min_class_size = int(np.median([count for count in initial_distribution.values()]))\n",
    "    \n",
    "    # If max_class_size is not specified, use the median class size * 2\n",
    "    if max_class_size is None:\n",
    "        max_class_size = min_class_size * 2\n",
    "    \n",
    "    # Apply SMOTE to classes below min_class_size\n",
    "    small_classes = {k: v for k, v in initial_distribution.items() if v < min_class_size}\n",
    "    if small_classes:\n",
    "        sampling_strategy = {k: min_class_size for k in small_classes.keys()}\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    else:\n",
    "        X_resampled, y_resampled = X.copy(), y.copy()\n",
    "    \n",
    "    # Random undersample classes above max_class_size\n",
    "    indices_to_keep = []\n",
    "    for class_label in np.unique(y_resampled):\n",
    "        class_indices = np.where(y_resampled == class_label)[0]\n",
    "        if len(class_indices) > max_class_size:\n",
    "            selected_indices = random.sample(list(class_indices), max_class_size)\n",
    "            indices_to_keep.extend(selected_indices)\n",
    "        else:\n",
    "            indices_to_keep.extend(class_indices)\n",
    "    \n",
    "    # Create final balanced dataset\n",
    "    X_balanced = X_resampled.iloc[indices_to_keep].reset_index(drop=True)\n",
    "    y_balanced = y_resampled[indices_to_keep]\n",
    "    \n",
    "    # Convert y back to one-hot encoding\n",
    "    race_df = pd.DataFrame(0, index=range(len(y_balanced)), columns=race_cols)\n",
    "    for i, label in enumerate(y_balanced):\n",
    "        race_df.iloc[i, label] = 1\n",
    "    \n",
    "    # Combine features with balanced races\n",
    "    final_df = pd.concat([X_balanced, race_df], axis=1)\n",
    "    \n",
    "    # Get final class distribution\n",
    "    final_distribution = dict(Counter(y_balanced))\n",
    "    \n",
    "    class_changes = {\n",
    "        'initial_distribution': initial_distribution,\n",
    "        'final_distribution': final_distribution\n",
    "    }\n",
    "    \n",
    "    return final_df, class_changes\n",
    "\n",
    "balanced_df, distribution = balance_cat_races(\n",
    "    df, \n",
    "    min_class_size=100,  \n",
    "    max_class_size=200\n",
    ")\n",
    "\n",
    "# Print class distribution changes\n",
    "print(\"Before:\", distribution['initial_distribution'])\n",
    "print(\"After:\", distribution['final_distribution'])\n"
   ],
   "id": "605534c01b0618c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: {2: 149, 8: 173, 4: 920, 7: 122, 6: 435, 9: 195, 0: 215, 5: 178, 3: 28, 10: 23, 1: 173, 11: 52, 13: 25, 12: 68}\n",
      "After: {0: 200, 1: 173, 2: 149, 3: 100, 4: 200, 5: 178, 6: 200, 7: 122, 8: 173, 9: 195, 10: 100, 11: 100, 12: 100, 13: 100}\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:17:20.212101Z",
     "start_time": "2024-11-12T22:17:07.797545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_data(df):\n",
    "    # Separate features and labels\n",
    "    # Get all race columns\n",
    "    race_columns = [col for col in df.columns if col.startswith('Race_')]\n",
    "    \n",
    "    # Get all non-race columns except the race columns\n",
    "    feature_columns = [col for col in df.columns if not col.startswith('Race_')]\n",
    "    \n",
    "    X = df[feature_columns].copy()\n",
    "    y = df[race_columns].copy()\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(df):\n",
    "    # Prepare the data\n",
    "    X_train, X_test, y_train, y_test, scaler = prepare_data(df)\n",
    "    \n",
    "    # Create the model\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    num_classes = y_train.shape[1]\n",
    "    model = create_model(input_shape, num_classes)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return model, scaler, history\n",
    "\n",
    "def predict_breed(model, scaler, input_data):\n",
    "    # Scale the input data\n",
    "    scaled_input = scaler.transform(input_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(scaled_input)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Load your data into a pandas DataFrame called 'df'\n",
    "model, scaler, history = train_model(df)\n",
    "\n"
   ],
   "id": "941d923efccd251b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihai\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - 49ms/step - accuracy: 0.2377 - loss: 0.3480 - val_accuracy: 0.3537 - val_loss: 0.2164\n",
      "Epoch 2/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3193 - loss: 0.2241 - val_accuracy: 0.3560 - val_loss: 0.2115\n",
      "Epoch 3/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3279 - loss: 0.2175 - val_accuracy: 0.3628 - val_loss: 0.2078\n",
      "Epoch 4/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3443 - loss: 0.2119 - val_accuracy: 0.3537 - val_loss: 0.2067\n",
      "Epoch 5/50\n",
      "56/56 - 0s - 4ms/step - accuracy: 0.3415 - loss: 0.2088 - val_accuracy: 0.3605 - val_loss: 0.2076\n",
      "Epoch 6/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3539 - loss: 0.2078 - val_accuracy: 0.3537 - val_loss: 0.2076\n",
      "Epoch 7/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3528 - loss: 0.2059 - val_accuracy: 0.3560 - val_loss: 0.2059\n",
      "Epoch 8/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3596 - loss: 0.2035 - val_accuracy: 0.3605 - val_loss: 0.2067\n",
      "Epoch 9/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3613 - loss: 0.2025 - val_accuracy: 0.3605 - val_loss: 0.2070\n",
      "Epoch 10/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3908 - loss: 0.1999 - val_accuracy: 0.3605 - val_loss: 0.2080\n",
      "Epoch 11/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3761 - loss: 0.1993 - val_accuracy: 0.3628 - val_loss: 0.2073\n",
      "Epoch 12/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3732 - loss: 0.1985 - val_accuracy: 0.3583 - val_loss: 0.2084\n",
      "Epoch 13/50\n",
      "56/56 - 0s - 4ms/step - accuracy: 0.3891 - loss: 0.1954 - val_accuracy: 0.3515 - val_loss: 0.2084\n",
      "Epoch 14/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3744 - loss: 0.1962 - val_accuracy: 0.3515 - val_loss: 0.2080\n",
      "Epoch 15/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3806 - loss: 0.1943 - val_accuracy: 0.3628 - val_loss: 0.2078\n",
      "Epoch 16/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3953 - loss: 0.1926 - val_accuracy: 0.3560 - val_loss: 0.2089\n",
      "Epoch 17/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3880 - loss: 0.1928 - val_accuracy: 0.3492 - val_loss: 0.2097\n",
      "Epoch 18/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4073 - loss: 0.1911 - val_accuracy: 0.3537 - val_loss: 0.2110\n",
      "Epoch 19/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4056 - loss: 0.1896 - val_accuracy: 0.3469 - val_loss: 0.2116\n",
      "Epoch 20/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4107 - loss: 0.1887 - val_accuracy: 0.3401 - val_loss: 0.2131\n",
      "Epoch 21/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3897 - loss: 0.1875 - val_accuracy: 0.2948 - val_loss: 0.2149\n",
      "Epoch 22/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4152 - loss: 0.1870 - val_accuracy: 0.3515 - val_loss: 0.2126\n",
      "Epoch 23/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.3988 - loss: 0.1846 - val_accuracy: 0.3197 - val_loss: 0.2140\n",
      "Epoch 24/50\n",
      "56/56 - 0s - 4ms/step - accuracy: 0.4294 - loss: 0.1838 - val_accuracy: 0.3379 - val_loss: 0.2151\n",
      "Epoch 25/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4453 - loss: 0.1808 - val_accuracy: 0.3333 - val_loss: 0.2158\n",
      "Epoch 26/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4373 - loss: 0.1811 - val_accuracy: 0.3333 - val_loss: 0.2167\n",
      "Epoch 27/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4334 - loss: 0.1802 - val_accuracy: 0.3311 - val_loss: 0.2177\n",
      "Epoch 28/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4458 - loss: 0.1774 - val_accuracy: 0.3061 - val_loss: 0.2195\n",
      "Epoch 29/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4566 - loss: 0.1768 - val_accuracy: 0.3039 - val_loss: 0.2185\n",
      "Epoch 30/50\n",
      "56/56 - 0s - 4ms/step - accuracy: 0.4447 - loss: 0.1760 - val_accuracy: 0.2993 - val_loss: 0.2214\n",
      "Epoch 31/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4464 - loss: 0.1752 - val_accuracy: 0.3447 - val_loss: 0.2193\n",
      "Epoch 32/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4691 - loss: 0.1730 - val_accuracy: 0.3129 - val_loss: 0.2210\n",
      "Epoch 33/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4481 - loss: 0.1740 - val_accuracy: 0.3175 - val_loss: 0.2210\n",
      "Epoch 34/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4583 - loss: 0.1727 - val_accuracy: 0.3243 - val_loss: 0.2218\n",
      "Epoch 35/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4685 - loss: 0.1712 - val_accuracy: 0.3379 - val_loss: 0.2234\n",
      "Epoch 36/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4719 - loss: 0.1683 - val_accuracy: 0.3243 - val_loss: 0.2255\n",
      "Epoch 37/50\n",
      "56/56 - 0s - 4ms/step - accuracy: 0.4719 - loss: 0.1690 - val_accuracy: 0.3107 - val_loss: 0.2242\n",
      "Epoch 38/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4708 - loss: 0.1685 - val_accuracy: 0.2789 - val_loss: 0.2270\n",
      "Epoch 39/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4799 - loss: 0.1680 - val_accuracy: 0.2880 - val_loss: 0.2274\n",
      "Epoch 40/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4787 - loss: 0.1651 - val_accuracy: 0.3039 - val_loss: 0.2269\n",
      "Epoch 41/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4923 - loss: 0.1636 - val_accuracy: 0.3129 - val_loss: 0.2281\n",
      "Epoch 42/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4969 - loss: 0.1626 - val_accuracy: 0.3265 - val_loss: 0.2299\n",
      "Epoch 43/50\n",
      "56/56 - 0s - 4ms/step - accuracy: 0.4782 - loss: 0.1661 - val_accuracy: 0.3288 - val_loss: 0.2275\n",
      "Epoch 44/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.5139 - loss: 0.1590 - val_accuracy: 0.2812 - val_loss: 0.2314\n",
      "Epoch 45/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.5105 - loss: 0.1613 - val_accuracy: 0.2857 - val_loss: 0.2324\n",
      "Epoch 46/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.4957 - loss: 0.1594 - val_accuracy: 0.3107 - val_loss: 0.2308\n",
      "Epoch 47/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.5179 - loss: 0.1573 - val_accuracy: 0.2925 - val_loss: 0.2331\n",
      "Epoch 48/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.5213 - loss: 0.1545 - val_accuracy: 0.3061 - val_loss: 0.2348\n",
      "Epoch 49/50\n",
      "56/56 - 0s - 4ms/step - accuracy: 0.4991 - loss: 0.1590 - val_accuracy: 0.3084 - val_loss: 0.2342\n",
      "Epoch 50/50\n",
      "56/56 - 0s - 3ms/step - accuracy: 0.5218 - loss: 0.1545 - val_accuracy: 0.3084 - val_loss: 0.2353\n",
      "\n",
      "Test accuracy: 0.2844\n"
     ]
    }
   ],
   "execution_count": 129
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
